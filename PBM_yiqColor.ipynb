{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTING\n",
    "import cv2\n",
    "from skimage.filters import gaussian\n",
    "from scipy.signal import firwin\n",
    "\n",
    "from numpy.fft import fft, ifft\n",
    "from numpy.fft import fft2, fftshift, ifft2, ifftshift\n",
    "from numpy import tile, real, min, zeros\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import openpyxl\n",
    "import time\n",
    "\n",
    "M_PI = math.pi\n",
    "eps = 2**(-52)\n",
    "\n",
    "START_whole = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## Parameter Initializing ################################\n",
    "videoName = 'cantilever (2200fps)'\n",
    "videoType = '.mp4'\n",
    "\n",
    "Low_Freq = 350\n",
    "High_Freq = 370\n",
    "alpha = 5\n",
    "Sampling_Rate = 2200\n",
    "\n",
    "refFrame = 0\n",
    "NumberOfPyramid = 2\n",
    "Orientation = 2\n",
    "sigma = 1\n",
    "attenuateOtherFreq = 0 # 영역 외 주파수에 대해 베재할 것인가에 대해 True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Mining Tools #####################################\n",
    "def LOGGING(n):\n",
    "    print('line {} passed'.format(n))\n",
    "\n",
    "def timeTIC():\n",
    "    START = time.time()\n",
    "    return START\n",
    "\n",
    "def timeTOK(n, START):\n",
    "    print('process {} done / delay: {}'.format(n, time.time()-START))\n",
    "\n",
    "\n",
    "def xlsxSave (savingName, data):\n",
    "    #data = np.array(data)\n",
    "    wb = openpyxl.Workbook()\n",
    "    sheet = wb.active\n",
    "\n",
    "    for x in range(data.shape[1]):\n",
    "        for y in range(data.shape[0]):\n",
    "            sheet.cell(row=x + 1, column=y + 1).value = data[y][x]\n",
    "\n",
    "    wb.save('./data/{}.xlsx'.format(savingName))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Filter Functions ######################\n",
    "\n",
    "def getFilters(dimension, rVals, orientations):\n",
    "    X = int(dimension[1])\n",
    "    Y = int(dimension[0])\n",
    "\n",
    "    defaultTwidth = 1\n",
    "\n",
    "    twidth = defaultTwidth\n",
    "\n",
    "    polarGrid = getPolarGrid(dimension)\n",
    "    count = 0\n",
    "\n",
    "    angle = np.array(polarGrid[0]) #픽셀 위치별 각도 값\n",
    "    rad = np.array(polarGrid[1]) #픽셀 위치별 거리 값\n",
    "\n",
    "    mask = getRadialMaskPair(rVals[0], rad, twidth)\n",
    "    himask = mask[0]\n",
    "    lomaskPrev = mask[1]\n",
    "\n",
    "\n",
    "\n",
    "    filters = []\n",
    "    filters.append(himask)\n",
    "\n",
    "    for k in range(1, len(rVals)):\n",
    "        mask = getRadialMaskPair(rVals[k], rad, twidth)\n",
    "        himask = mask[0]\n",
    "        lomask = mask[1]\n",
    "\n",
    "        radMask = himask*lomaskPrev\n",
    "\n",
    "        for j in range(1, orientations+1):\n",
    "            angleMask = getAngleMask(j, orientations, angle)\n",
    "            filters.append(radMask*angleMask/2)\n",
    "\n",
    "        lomaskPrev = lomask\n",
    "    filters.append(lomask)\n",
    "\n",
    "    for k in range(len(filters)):\n",
    "        filters[k] = np.array(filters[k])\n",
    "    return filters\n",
    "\n",
    "def getPolarGrid(dimension):\n",
    "    X = dimension[1]\n",
    "    Y = dimension[0]\n",
    "    centerX = int(X / 2)\n",
    "    centerY = int(Y / 2)\n",
    "\n",
    "    # Create rectangular grid\n",
    "    xramp = np.array([ [(x-int(X/2))/(X/2) for x in range(X)] for y in range(Y)])\n",
    "    yramp = np.array([ [(y-int(Y/2))/(Y/2) for x in range(X)] for y in range(Y)])\n",
    "    angle = np.arctan2(xramp, yramp)+M_PI/2\n",
    "\n",
    "    rad = np.sqrt(xramp**2+yramp**2)\n",
    "    rad[centerY][centerX] = rad[centerY-1][centerX]\n",
    "\n",
    "    polarGrid = [angle, rad]\n",
    "    return polarGrid\n",
    "\n",
    "\n",
    "def getRadialMaskPair(r, rad, twidth): #3차원 그래프상으로 보이는 완전 꼬깔 형태에서, 위 아래의 범위를 잘라내고 원뿔대 같은 형태도 만든다.\n",
    "    X = int(rad.shape[1])\n",
    "    Y = int(rad.shape[0])\n",
    "\n",
    "    log_rad = np.log2(rad)-np.log2(r)\n",
    "\n",
    "    himask = log_rad\n",
    "    himask[himask>0] = 0\n",
    "    himask[himask<-twidth] = -twidth\n",
    "    himask = himask*M_PI/(2*twidth)\n",
    "\n",
    "    himask = np.cos(himask)\n",
    "    lomask = np.sqrt(1-himask**2)\n",
    "\n",
    "    mask = [himask, lomask]\n",
    "    return mask\n",
    "\n",
    "def getAngleMask(b, orientations, angle):\n",
    "    order = orientations - 1\n",
    "    const = (2 ** (2 * order)) * (math.factorial(order) ** 2) / (orientations * math.factorial(2 * order)) # Scaling constant\n",
    "\n",
    "    angle_ = (M_PI + angle - (M_PI * (b - 1) / orientations)) % (2 * M_PI) - M_PI\n",
    "    anglemask = 2 * np.sqrt(const) * (np.cos(angle_) ** order) * (abs(angle_) < (M_PI / 2))  # Make falloff smooth\n",
    "    return anglemask\n",
    "\n",
    "def getFilterIDX2(filters, orientations, rVals):\n",
    "    X = filters[0].shape[1]\n",
    "    Y = filters[0].shape[0]\n",
    "    nFilts = len(filters)\n",
    "    filtIDX = [[None for j in range(orientations)] for i in range(nFilts)]\n",
    "    croppedFilters = []\n",
    "\n",
    "    #himask IDX\n",
    "    filtIDX[0][0] = [y for y in range(Y)]\n",
    "    filtIDX[0][1] = [x for x in range(X)]\n",
    "    croppedFilters.append(filters[0])\n",
    "\n",
    "    #stearable filter IDX\n",
    "    for k in range(1, nFilts-1, orientations):\n",
    "        n = int(k/2)+1\n",
    "        lb_y = int( (Y*(sum(rVals[0:n])-1))/2 )\n",
    "        ub_y = Y - lb_y\n",
    "        lb_x = int( (X*(sum(rVals[0:n])-1))/2 )\n",
    "        ub_x = X - lb_x\n",
    "\n",
    "        for i in range(orientations):\n",
    "            filtIDX[k+i][0] = [y + lb_y for y in range(ub_y - lb_y)]\n",
    "            filtIDX[k+i][1] = [x + lb_x for x in range(ub_x - lb_x)]\n",
    "\n",
    "        for i in range(orientations):\n",
    "            croppedFilters.append(filters[k+i][lb_y:ub_y, lb_x:ub_x])\n",
    "\n",
    "\n",
    "    #lomaskIDX\n",
    "    lb_y = int( (Y * (sum(rVals) - 1))/2 )\n",
    "    ub_y = Y - lb_y\n",
    "    lb_x = int( (X * (sum(rVals) - 1))/2 )\n",
    "    ub_x = X - lb_x\n",
    "\n",
    "\n",
    "    filtIDX[nFilts - 1][0] = [y + lb_y for y in range(ub_y - lb_y)]\n",
    "    filtIDX[nFilts - 1][1] = [x + lb_x for x in range(ub_x - lb_x)]\n",
    "    croppedFilters.append(filters[nFilts-1][lb_y:ub_y, lb_x:ub_x])\n",
    "\n",
    "    filterIDX = [croppedFilters, filtIDX]\n",
    "    return filterIDX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fir_window_bp_2(delta, fl, fh):\n",
    "    length = delta.shape[0]+1\n",
    "    b = firwin(length, (fl * 2, fh * 2), pass_zero=False)[0:length-1]\n",
    "\n",
    "    m = delta.shape[1]\n",
    "    batches = 20\n",
    "    batch_size = int(m / batches) + 1\n",
    "    temp = fft(ifftshift(b))\n",
    "    out = zeros(delta.shape, dtype=delta.dtype)\n",
    "\n",
    "    i=0\n",
    "    indexes = (batch_size * i, min((batch_size * (i + 1), m)))\n",
    "    while (indexes[0]<m):\n",
    "        indexes = (batch_size * i, min((batch_size * (i + 1), m)))\n",
    "        freq = fft(delta[:, indexes[0]:indexes[1]], axis=0) * tile(temp, (\n",
    "            delta.shape[2], indexes[1] - indexes[0], 1)).swapaxes(0, 2)\n",
    "        out[:, indexes[0]:indexes[1]] = real(ifft(freq, axis=0))\n",
    "        i += 1\n",
    "        indexes = (batch_size * i, min((batch_size * (i + 1), m)))\n",
    "    return out\n",
    "\n",
    "def amplitude_weighted_blur(x, weight, sigma):\n",
    "    if sigma != 0:\n",
    "        return gaussian(x*weight, sigma, mode=\"wrap\") / gaussian(weight, sigma, mode=\"wrap\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Color Channel Functions #####################\n",
    "# OpenCV에서 따로 YIQ관련 변환 알고리즘을 지원하지 않아서 mathwork 공식 계산 수치들을 들고와 대입했다.\n",
    "# HSV가 V가 grayscale과 같은 방식으로 명암을 저장하기 때문에, YIQ의 Y와 동일한 역할을 한다. \n",
    "# 그러나 Hue, Saturation에 대한 부분 때문인지 HSV의 경우는 원본 영상의 형상이 뚜렷하게 남아있어 결과물이 이상하다.\n",
    "\n",
    "# Y는 Luminescence로 Brightness(명암)을 의미한다.\n",
    "# I는 red~cyan의 hue(색조)값을 의미한다, Q는 green~magenta의 hue 값을 의미한다.\n",
    "# 즉 HSV와 달리 saturation(채도)는 취급하지 않으며, hue를 사이클 적으로 다르는 HSV와 달리 두개의 boundary가 뚜렷한 색조로써 취급한다.\n",
    "# 이에 따라 배포 코드에서 제시한 YIQ 좌표를 따른다.\n",
    "\n",
    "def bgr2yiq(img):\n",
    "    R = img[:, :, 2]\n",
    "    G = img[:, :, 1]\n",
    "    B = img[:, :, 0]\n",
    "\n",
    "    Y = 0.299 * R + 0.587 * G + 0.114 * B\n",
    "    I = 0.596 * R - 0.274 * G - 0.322 * B\n",
    "    Q = 0.211 * R - 0.523 * G + 0.312 * B\n",
    "\n",
    "    img_yiq = np.zeros([img.shape[0], img.shape[1], img.shape[2]])\n",
    "    img_yiq[:, :, 0] = Y\n",
    "    img_yiq[:, :, 1] = I\n",
    "    img_yiq[:, :, 2] = Q\n",
    "    #YIQ = np.array([[0.299, 0.587, 0.114],[0.596, -0.274, -0.322],[0.211, -0.523, 0.312]])\n",
    "    return img_yiq\n",
    "\n",
    "def yiq2bgr(img):\n",
    "    Y = img[:, :, 0]\n",
    "    I = img[:, :, 1]\n",
    "    Q = img[:, :, 2]\n",
    "\n",
    "    R = Y+0.956*I+0.621*Q\n",
    "    G = Y-0.272*I-0.647*Q\n",
    "    B = Y-1.106*I+1.703*Q\n",
    "\n",
    "    img_rgb = np.zeros([img.shape[0], img.shape[1], img.shape[2]])\n",
    "    img_rgb[:, :, 0] = B\n",
    "    img_rgb[:, :, 1] = G\n",
    "    img_rgb[:, :, 2] = R\n",
    "    #YIQ = np.array([[0.299, 0.587, 0.114],[0.596, -0.274, -0.322],[0.211, -0.523, 0.312]])\n",
    "    return img_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 0.Create Stearable Filter, Initializing done / delay: 0.4740269184112549\n"
     ]
    }
   ],
   "source": [
    "START = timeTIC()\n",
    "\n",
    "filename = './input/{}{}'.format(videoName, videoType)\n",
    "\n",
    "cap_original = cv2.VideoCapture(filename)\n",
    "\n",
    "####################################### RGB to Gray Scale (save)\n",
    "ret, frame = cap_original.read()\n",
    "frameX = frame.shape[1]\n",
    "frameY = frame.shape[0]\n",
    "nColor = frame.shape[2]\n",
    "nFrame = 0\n",
    "\n",
    "while(True):\n",
    "    if ret == False:\n",
    "        break\n",
    "    else:\n",
    "        nFrame += 1\n",
    "    ret, frame = cap_original.read()\n",
    "\n",
    "cap_original.release()\n",
    "\n",
    "pyrLayers = 2\n",
    "rVals = [1]\n",
    "for i in range(pyrLayers):\n",
    "    rVals.append(0.5**(i+1))\n",
    "\n",
    "\n",
    "####################################### Create Steerable Filter##########\n",
    "filters = getFilters([frameY, frameX], rVals, Orientation)\n",
    "filterIDX = getFilterIDX2(filters, Orientation, rVals)\n",
    "croppedFilters = filterIDX[0]\n",
    "filtIDX = filterIDX[1]\n",
    "\n",
    "\n",
    "###########################Initialization of motion magnified luma component\n",
    "\n",
    "magnifiedLumaFFT = np.zeros([nFrame, frameY, frameX], dtype=np.complex64)\n",
    "\n",
    "\n",
    "\n",
    "timeTOK('0.Create Stearable Filter, Initializing', START)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 1.Spatial Fourier Transform done / delay: 8.347477436065674\n"
     ]
    }
   ],
   "source": [
    "START = timeTIC()\n",
    "\n",
    "################################ Spatial Fourier Transform ########################################\n",
    "numLevels = len(filters)\n",
    "vidFFT = np.zeros([nFrame,frameY,frameX], dtype=np.complex64)\n",
    "# vidFFT[0] = saturation, vidFFT[1] = value\n",
    "\n",
    "cap_original = cv2.VideoCapture(filename)\n",
    "ret, frame = cap_original.read()\n",
    "\n",
    "for k in range(0, nFrame):\n",
    "    clipMat = frame/255\n",
    "    tVid = bgr2yiq(clipMat)[:,:,0]\n",
    "    vidFFT[k] = fftshift(fft2(tVid))\n",
    "    ret, frame = cap_original.read()\n",
    "\n",
    "\n",
    "cap_original.release()\n",
    "\n",
    "\n",
    "timeTOK('1.Spatial Fourier Transform', START)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1 succeeded\n",
      "level 2 succeeded\n",
      "level 3 succeeded\n",
      "level 4 succeeded\n",
      "process 2~4.Compute Phase of Level~ done / delay: 70.05500674247742\n"
     ]
    }
   ],
   "source": [
    "START = timeTIC()\n",
    "\n",
    "##################################Compute Phase Of level#######\n",
    "for level in range(1, numLevels-1):\n",
    "    X = len(croppedFilters[level][0])\n",
    "    Y = len(croppedFilters[level])\n",
    "    lb_x = filtIDX[level][1][0]\n",
    "    ub_x = filtIDX[level][1][-1]+1\n",
    "    lb_y = filtIDX[level][0][0]\n",
    "    ub_y = filtIDX[level][0][-1]+1\n",
    "\n",
    "\n",
    "    clipMat = croppedFilters[level] * vidFFT[refFrame][lb_y:ub_y, lb_x:ub_x]  # MATLAB과는 좌우 반전\n",
    "    pyrRef = ifft2(ifftshift(clipMat))\n",
    "    pyrRefPhaseOrig = pyrRef / abs(pyrRef)\n",
    "    pyrRef = np.angle(pyrRef)\n",
    "\n",
    "    delta = np.zeros([nFrame,Y,X], dtype=np.float16)\n",
    "    matCheck = []\n",
    "    for frameIDX in range(0, nFrame):\n",
    "        filterResponse = ifft2(ifftshift( croppedFilters[level] * vidFFT[frameIDX][lb_y:ub_y, lb_x:ub_x] ))\n",
    "        pyrCurrent = np.angle(filterResponse)\n",
    "        clipMat1 = pyrCurrent - pyrRef\n",
    "        clipMat2 = M_PI + clipMat1\n",
    "        clipMat3 = clipMat2%(2*M_PI)\n",
    "        clipMat4 = clipMat3 - M_PI\n",
    "        clipMat = clipMat4\n",
    "        delta[frameIDX] = clipMat\n",
    "\n",
    "\n",
    "    ####### Temporal Filtering\n",
    "    delta_1 = fir_window_bp_2(delta, Low_Freq / Sampling_Rate, High_Freq / Sampling_Rate)  # Finite Impulse Response filter\n",
    "\n",
    "\n",
    "    ####### Apply magnification\n",
    "    for frameIDX in range(0, nFrame):\n",
    "        Phase = delta_1[frameIDX]\n",
    "\n",
    "        originalLevel = ifft2(ifftshift(croppedFilters[level]*vidFFT[frameIDX][lb_y:ub_y, lb_x:ub_x]))\n",
    "\n",
    "        if (sigma != 0):\n",
    "            Phase = amplitude_weighted_blur(Phase, abs(originalLevel)+eps, sigma)\n",
    "\n",
    "        Phase = alpha*Phase\n",
    "\n",
    "        if (attenuateOtherFreq):\n",
    "            tempOrig = abs(originalLevel)*pyrRefPhaseOrig\n",
    "        else:\n",
    "            tempOrig = originalLevel\n",
    "\n",
    "        tempTransformOut = np.exp(1j*Phase)*tempOrig\n",
    "\n",
    "\n",
    "        A = croppedFilters[level]\n",
    "        B = fftshift(fft2(tempTransformOut))\n",
    "        curLevelFrame = 2 * A * B\n",
    "\n",
    "        matClip = magnifiedLumaFFT[frameIDX][lb_y:ub_y, lb_x:ub_x]\n",
    "        magnifiedLumaFFT[frameIDX][lb_y:ub_y, lb_x:ub_x] = matClip + curLevelFrame\n",
    "\n",
    "\n",
    "    print('level {} succeeded'.format(level))\n",
    "\n",
    "    \n",
    "timeTOK('2~4.Compute Phase of Level~', START)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process 5. Final Process done / delay: 12.062689781188965\n"
     ]
    }
   ],
   "source": [
    "START = timeTIC()\n",
    "\n",
    "\n",
    "##################################Add unmolested lowpass residual#####\n",
    "level = len(filters)-1\n",
    "lb_x = filtIDX[level][1][0]\n",
    "ub_x = filtIDX[level][1][-1] + 1\n",
    "lb_y = filtIDX[level][0][0]\n",
    "ub_y = filtIDX[level][0][-1] + 1\n",
    "for frameIDX in range(0, nFrame):\n",
    "    lowpassFrame = vidFFT[frameIDX][lb_y:ub_y, lb_x:ub_x]*(croppedFilters[level]**2)\n",
    "    matClip = magnifiedLumaFFT[frameIDX][lb_y:ub_y, lb_x:ub_x] + lowpassFrame\n",
    "    magnifiedLumaFFT[frameIDX][lb_y:ub_y, lb_x:ub_x] = matClip\n",
    "\n",
    "##########################Saving\n",
    "cap_original = cv2.VideoCapture(fileName)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "obj_out = cv2.VideoWriter('./output/(color) '+ str(Low_Freq) + '~' + str(High_Freq) + ', a=' + str(alpha) + ' {}.mp4'.format(videoName)\n",
    "                          , fourcc, 30.0, (frameX, frameY))\n",
    "\n",
    "ret, frame = cap_original.read()\n",
    "\n",
    "for k in range(0, nFrame):\n",
    "    clipMat1 = magnifiedLumaFFT[k]\n",
    "    clipMat = ifft2(ifftshift(clipMat1))\n",
    "    magnifiedLuma = np.real(clipMat)\n",
    "    #명암에 대한 데이터만 적용하기 위해 yiq변환해서 Y 값만 가져온다.\n",
    "    clipMat2 = bgr2yiq(frame)\n",
    "    clipMat3 = magnifiedLuma*255\n",
    "    clipMat2[:,:,0] = clipMat3\n",
    "    \n",
    "    #그 외의 Q, I는 그대로 사용할 것이므로 변환된 Y만 원본 영상에 대입한 뒤 다시 RGB로 변환한다.\n",
    "    outFrame = yiq2bgr(clipMat2)\n",
    "    \n",
    "    outFrame[outFrame > 255] = 255\n",
    "    outFrame[outFrame < 0] = 0\n",
    "    outFrame = np.uint8(outFrame)\n",
    "    #outFrame = np.uint8(yiq2bgr(clipMat2))\n",
    "\n",
    "    obj_out.write(outFrame)\n",
    "    ret, frame = cap_original.read()\n",
    "\n",
    "\n",
    "timeTOK('5. Final Process', START)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole Process Finished / delay: 91.13321232795715\n"
     ]
    }
   ],
   "source": [
    "cap_original.release()\n",
    "obj_out.release()\n",
    "\n",
    "print('Whole Process Finished / delay: {}'.format(time.time()-START_whole))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
